# RAG Chatbot for Government Data â€” Python + LangChain + Qdrant

This project is a practical implementation of a **Retrieval-Augmented Generation (RAG)** system based on Large Language Models (LLMs), designed to operate on real public data. It consists of two main modules:

- **`load_to_qdrant.py`** â€“ loads CSV/XLSX data, transforms rows into embeddings, and stores them in a Qdrant vector database.
- **`rag_chatbot.py`** â€“ a formal chatbot (styled as a public official) powered by GPT-3.5-Turbo that dynamically retrieves relevant data chunks to answer user queries.

The system enables users to **ask natural language questions in Polish** and receive **accurate, source-based answers only**. It demonstrates a production-grade example of using LLMs in environments where information traceability and reliability are crucial.

---

## ğŸ”§ Technologies

- **LangChain** â€“ for prompt management, chain orchestration, and integration with Qdrant.
- **OpenAI / GPT-3.5 Turbo** â€“ LLM used for generating answers.
- **Qdrant (local)** â€“ vector database for embedding storage and retrieval.
- **Python + Pandas** â€“ for processing structured tabular data from CSV and Excel files.
- **OpenAI Embeddings** â€“ for semantic encoding of tabular records into vectors.

---

## ğŸ§  Features

### 1. `load_to_qdrant.py` â€“ Data ingestion to vector database

- Automatically detects `.csv` and `.xlsx` files from the `cleaned/` folder.
- Maps each file to a distinct **Qdrant collection** based on content type (e.g. `geologia_sejsmika`, `finanse_publiczne`).
- Generates embeddings for each row using **OpenAIâ€™s `text-embedding-3-large`** model.
- Uses `CharacterTextSplitter` to chunk large rows for efficient semantic search.
- Creates Qdrant collections if they don't already exist.
- Stores each chunk as a document, tagged with metadata about the original file.

### 2. `rag_chatbot.py` â€“ Context-aware chatbot with selective retrieval

- Accepts open-ended questions from users in natural Polish.
- Dynamically selects the most relevant data collection based on a semantic prompt (`select_chain`).
- Retrieves the top-k relevant chunks from Qdrant using `RetrievalQA`.
- Answers are generated in a **formal, precise, and official tone** â€” mimicking a government clerk.
- If insufficient information is found in the documents, the model responds clearly with: *"Nie posiadam wystarczajÄ…cych informacji..."*

---

## ğŸ“ Project structure

```text
project/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ rag_chatbot.py          # chatbot with collection selector
â”œâ”€â”€ loaders/
â”‚   â””â”€â”€ load_to_qdrant.py       # ingest data into Qdrant
â”œâ”€â”€ cleaned/                    # folder with cleaned tabular files
â”œâ”€â”€ .env                        # (local) OpenAI key and config
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


# RAG Chatbot dla danych rzÄ…dowych â€” Python + LangChain + Qdrant

Ten projekt to praktyczna implementacja systemu **RAG (Retrieval-Augmented Generation)** opartego na duÅ¼ych modelach jÄ™zykowych (LLM), ktÃ³ry dziaÅ‚a na rzeczywistych danych publicznych. SkÅ‚ada siÄ™ z dwÃ³ch gÅ‚Ã³wnych moduÅ‚Ã³w:

- **`load_to_qdrant.py`** â€“ Å‚adowanie danych CSV/XLSX, przeksztaÅ‚canie ich w embeddingi i zapis do bazy wektorowej Qdrant.
- **`rag_chatbot.py`** â€“ chatbot urzÄ™dowy oparty na GPT-3.5-Turbo, ktÃ³ry selektywnie pobiera kontekst z bazy i udziela odpowiedzi na pytania uÅ¼ytkownika.

System umoÅ¼liwia **zadawanie naturalnych pytaÅ„ w jÄ™zyku polskim** i udzielanie precyzyjnych odpowiedzi **wyÅ‚Ä…cznie na podstawie zaÅ‚adowanych danych**. Idealny przykÅ‚ad zastosowania LLM w Å›rodowisku, gdzie waÅ¼na jest kontrola ÅºrÃ³dÅ‚a informacji.

---

## ğŸ”§ Technologie

- **LangChain** â€“ do zarzÄ…dzania Å‚aÅ„cuchami zapytaÅ„, promptÃ³w i integracji z Qdrant.
- **OpenAI / GPT-3.5 Turbo** â€“ model LLM do generowania odpowiedzi.
- **Qdrant (local)** â€“ lokalna baza wektorowa do przechowywania embeddingÃ³w.
- **Python + Pandas** â€“ przetwarzanie danych tabularnych z CSV/XLSX.
- **OpenAI Embeddings** â€“ przeksztaÅ‚canie rekordÃ³w danych w wektory semantyczne.

---

## ğŸ§  Funkcje

### 1. `load_to_qdrant.py` â€“ Å‚adowanie danych do bazy wektorowej

- Automatycznie rozpoznaje pliki `.csv` i `.xlsx` w folderze `cleaned/`.
- Mapuje kaÅ¼dy plik do osobnej **kolekcji Qdranta** wedÅ‚ug typu danych (np. `geologia_sejsmika`, `finanse_publiczne`).
- Tworzy embeddingi dla kaÅ¼dego rekordu przy uÅ¼yciu **OpenAI Embeddings (text-embedding-3-large)**.
- UÅ¼ywa `CharacterTextSplitter`, aby lepiej indeksowaÄ‡ dane o duÅ¼ej dÅ‚ugoÅ›ci.
- Tworzy kolekcje w Qdrant, jeÅ›li nie istniejÄ….
- Przechowuje dokumenty w postaci chunkÃ³w z metadanymi o ÅºrÃ³dle.

### 2. `rag_chatbot.py` â€“ chatbot z selektywnym kontekstem

- UÅ¼ytkownik wpisuje pytanie w jÄ™zyku naturalnym.
- System najpierw wybiera wÅ‚aÅ›ciwÄ… kolekcjÄ™ danych na podstawie opisu (`select_chain`).
- NastÄ™pnie wykorzystuje `RetrievalQA` i Qdranta, aby pobraÄ‡ najbardziej relewantne fragmenty danych (k=5).
- Chatbot udziela **formalnych, precyzyjnych i bezpiecznych odpowiedzi** (symulujÄ…c urzÄ™dnika paÅ„stwowego).
- JeÅ›li dane nie zawierajÄ… odpowiedzi, model jasno informuje: *"Nie posiadam wystarczajÄ…cych informacji..."*

---

## ğŸ“ Struktura katalogÃ³w

```text
project/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ rag_chatbot.py          # chatbot z wyborem kolekcji
â”œâ”€â”€ loaders/
â”‚   â””â”€â”€ load_to_qdrant.py       # Å‚adowanie danych do Qdrant
â”œâ”€â”€ cleaned/                    # folder z oczyszczonymi plikami danych
â”œâ”€â”€ .env                        # (lokalny) klucz API
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
